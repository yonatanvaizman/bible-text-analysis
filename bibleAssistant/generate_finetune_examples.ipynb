{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce924eec",
   "metadata": {},
   "source": [
    "# Generate example conversations to fine-tune (and test) the LLM for BibleAssistant agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84dc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da580b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path().resolve()\n",
    "\n",
    "#sys.path.append(str(current_dir))\n",
    "sys.path.append(str(current_dir.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b2f3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import sefaria.sefaria_code as sef\n",
    "import bibleAssistant.agent as bagent\n",
    "import bibleAssistant.bible_tools as bblt\n",
    "import typo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d1ddb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a research assistant that always responds using a JSON object with fields \"tool\" and \"arguments\".\n",
      "\n",
      "To respond normally to the user, use:\n",
      "{\"tool\": \"respond_to_user\", \"arguments\":{\"text\": \"<text to show the user>\"}}\n",
      "\n",
      "To call a tool, use:\n",
      "{\"tool\": \"<tool_name>\", \"arguments\":{ ... }}\n",
      "\n",
      "After you call a tool, you will receive a message with role \"user\" containing a JSON object.\n",
      "The tool message always includes \"tool_name\" and \"status\".\n",
      "\n",
      "If \"status\" is \"ok\":\n",
      "- The message will include a \"result\" object.\n",
      "- Read \"result.text\".\n",
      "- Respond using \"respond_to_user\" and copy \"result.text\" exactly as-is.\n",
      "\n",
      "If \"status\" is \"error\":\n",
      "- The message will include an \"error_message\".\n",
      "- If the error message is clear enough (e.g., if the user spelled a book name wrong and it is clear which book the user intended), you can call the tool again with the corrected arguments.\n",
      "- Otherwise, respond using \"respond_to_user\" and copy \"error_message\" exactly as-is (to let the user tell you what to do next).\n",
      "\n",
      "Rules:\n",
      "- Never modify, translate, summarize, or explain text returned by the tool.\n",
      "- Never add commentary or extra text.\n",
      "- Never guess missing arguments.\n",
      "- Never correct user mistakes on the first attempt of a tool call.\n",
      "- Never retry a failed tool call with exactly the same arguments.\n",
      "\n",
      "Available tool:\n",
      "\n",
      "To get the text of a specific biblical verse:\n",
      "{\"tool\": \"lookup_verse\", \"arguments\":{\"version\":\"<version>\", book:\"<book>\", chapter_num:<integer>, verse_num:<integer>}}\n",
      "When this tool call succeeds, contains the verse. Copy it exactly as-is and return to the user with \"respond_to_user\".\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_agent = bagent.Agent(\"dummy\")\n",
    "system_prompt = dummy_agent.system_instructions\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d1d7fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_lookup_variations():\n",
    "    variations = [\n",
    "        \"Please get me the biblical verse from the book of {book}, version '{version}', chapter {chapter_num} verse {verse_num}\",\n",
    "        \"Give me verse {verse_num} from chapter {chapter_num} in the '{version}' version of {book}.\",\n",
    "        \"Get me {book} {chapter_num}:{verse_num} ('{version}' version).\",\n",
    "        \"Show me {book} chapter {chapter_num}, verse {verse_num}, in the '{version}' version.\",\n",
    "        \"I want to read {book} {chapter_num}:{verse_num} from the '{version}' version.\",\n",
    "        \"Lookup {book} {chapter_num}:{verse_num} in the '{version}' text.\",\n",
    "        \"Fetch the verse {chapter_num}:{verse_num} from {book} ({version}).\",\n",
    "        \"Could you retrieve {book} chapter {chapter_num} verse {verse_num} in '{version}'?\",\n",
    "        \"Please provide {book} {chapter_num}:{verse_num} from the '{version}' edition.\",\n",
    "        \"Give me the text of {book} {chapter_num}:{verse_num} in '{version}'.\",\n",
    "        \"Retrieve the verse {verse_num} in chapter {chapter_num} of {book}, '{version}' version.\",\n",
    "        \"I'd like to see {book} {chapter_num}:{verse_num} in the '{version}' translation.\",\n",
    "        \"Pull up {book} chapter {chapter_num}, verse {verse_num} ('{version}').\",\n",
    "        \"Can you get me {book} {chapter_num}:{verse_num} from the '{version}' version?\",\n",
    "        \"Please show {book} {chapter_num}:{verse_num} using the '{version}' version.\",\n",
    "        \"What does {book} {chapter_num}:{verse_num} say in the '{version}' version?\",\n",
    "        \"Give me the verse located at {book} {chapter_num}:{verse_num} ('{version}').\",\n",
    "        \"I'd like the '{version}' text for {book} {chapter_num}:{verse_num}.\"\n",
    "    ]\n",
    "    return variations\n",
    "\n",
    "def get_user_lookup_corrected_version_variations():\n",
    "    variations = [\n",
    "        \"oh sorry. try version {version}\",\n",
    "        \"i misspelled it should be {version}\",\n",
    "        \"use '{version}'\",\n",
    "        \"let me correct: {book} {chapter_num}:{verse_num} version '{version}'\",\n",
    "        \"oh then pick '{version}' version\"\n",
    "    ]\n",
    "    return variations\n",
    "\n",
    "def synth_lookup_verse_version_typo(book, version, chapter_num, verse_num):\n",
    "    typo_options = [\n",
    "        (typo.StrErrer(version).char_swap().result, 'char_swap'),\n",
    "        (typo.StrErrer(version).extra_char().result, 'extra_char'),\n",
    "        (typo.StrErrer(version).missing_char().result, 'missing_char'),\n",
    "        (typo.StrErrer(version).nearby_char().result, 'nearby_char'),\n",
    "        (typo.StrErrer(version).repeated_char().result, 'repeated_char')\n",
    "    ]\n",
    "    (wrong_version, typo_class) = random.choice(typo_options)\n",
    "\n",
    "    tool_name = dummy_agent.TOOL_LOOKUP_VERSE\n",
    "    wrong_args = {\n",
    "            \"version\": wrong_version,\n",
    "            \"book\": book,\n",
    "            \"chapter_num\": chapter_num,\n",
    "            \"verse_num\": verse_num\n",
    "        }\n",
    "    right_args = {\n",
    "            \"version\": version,\n",
    "            \"book\": book,\n",
    "            \"chapter_num\": chapter_num,\n",
    "            \"verse_num\": verse_num\n",
    "        }\n",
    "\n",
    "    user_req_variations = get_user_lookup_variations()\n",
    "    variation1 = int(np.random.choice(len(user_req_variations), 1)[0])\n",
    "    user_msg1 = user_req_variations[variation1].format_map(wrong_args)\n",
    "    llm_msg1 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_LOOKUP_VERSE,\n",
    "        dummy_agent.KEY_ARGS: wrong_args}, ensure_ascii=False)\n",
    "    try:\n",
    "        lookup_result_obj = bblt.lookup_verse(**wrong_args)\n",
    "        print(f\"!!! Suspicious. We expected this trial to fail because of wrong args ({typo_class}) {wrong_args}\")\n",
    "        return None\n",
    "    except Exception as ex:\n",
    "        error_msg = str(ex)\n",
    "\n",
    "    tool_msg1 = json.dumps({\n",
    "        \"tool_name\": tool_name,\n",
    "        \"status\": \"error\",\n",
    "        \"error_message\": error_msg\n",
    "    }, ensure_ascii=False)\n",
    "    llm_msg2 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_RESPOND_TO_USER,\n",
    "        dummy_agent.KEY_ARGS: {\"text\": error_msg}}, ensure_ascii=False)\n",
    "    \n",
    "    user_correct_variations = get_user_lookup_corrected_version_variations()\n",
    "    variation2 = int(np.random.choice(len(user_correct_variations), 1)[0])\n",
    "    user_msg2 = user_correct_variations[variation2].format_map(right_args)\n",
    "\n",
    "    llm_msg3 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_LOOKUP_VERSE,\n",
    "        dummy_agent.KEY_ARGS: right_args}, ensure_ascii=False)\n",
    "\n",
    "    try:\n",
    "        lookup_result_obj = bblt.lookup_verse(**right_args)\n",
    "        verse_text = lookup_result_obj[\"text\"]\n",
    "        if not isinstance(verse_text, str):\n",
    "            raise ValueError(\"Verse text must be a string\")\n",
    "    except Exception as ex:\n",
    "        print(f\"!!! Suspicious. We expected this to succeed, but got {str(ex)}\")\n",
    "        return None\n",
    "\n",
    "    tool_resp = json.dumps({\n",
    "        \"tool_name\": tool_name,\n",
    "        \"status\": \"ok\",\n",
    "        \"result\": lookup_result_obj\n",
    "    } ,ensure_ascii=False)\n",
    "    llm_msg4 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_RESPOND_TO_USER,\n",
    "        dummy_agent.KEY_ARGS: {\"text\": verse_text}}, ensure_ascii=False)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": dummy_agent.ROLE_SYSTEM, \"content\": dummy_agent.system_instructions},\n",
    "        {\"role\": dummy_agent.ROLE_USER, \"content\": user_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_TOOL, \"content\": tool_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg2},\n",
    "        {\"role\": dummy_agent.ROLE_USER, \"content\": user_msg2},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg3},\n",
    "        {\"role\": dummy_agent.ROLE_TOOL, \"content\": tool_resp},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg4}\n",
    "    ]\n",
    "    metadata = {\n",
    "        \"scenario\": \"lookup_verse_typo_version\",\n",
    "        \"variation1\": variation1,\n",
    "        \"variation2\": variation2,\n",
    "        \"typo_class\": typo_class,\n",
    "        \"wrong_args\": wrong_args,\n",
    "        \"right_args\": right_args\n",
    "    }\n",
    "    example = {\"metadata\": metadata, \"messages\": messages}\n",
    "    return example\n",
    "\n",
    "def synth_lookup_verse_book_typo(book, version, chapter_num, verse_num):\n",
    "    typo_options = [\n",
    "        (typo.StrErrer(book).char_swap().result, 'char_swap'),\n",
    "        (typo.StrErrer(book).extra_char().result, 'extra_char'),\n",
    "        (typo.StrErrer(book).missing_char().result, 'missing_char'),\n",
    "        (typo.StrErrer(book).nearby_char().result, 'nearby_char'),\n",
    "        (typo.StrErrer(book).repeated_char().result, 'repeated_char')\n",
    "    ]\n",
    "    typo_options = list(filter(lambda book_name:book_name not in bblt.supported_books, typo_options))\n",
    "    if not typo_options:\n",
    "        return None # All the typos by chance are valid book names\n",
    "    (wrong_book, typo_class) = random.choice(typo_options)\n",
    "    # More variations cap/small:\n",
    "    (wrong_book, typo_class) = random.choice([\n",
    "        (wrong_book, typo_class),\n",
    "        (wrong_book[0].upper() + wrong_book[1:], typo_class + \"_cap\"),\n",
    "        (wrong_book.upper(), typo_class + \"_allcaps\"),\n",
    "    ])\n",
    "\n",
    "    tool_name = dummy_agent.TOOL_LOOKUP_VERSE\n",
    "    wrong_args = {\n",
    "            \"version\": version,\n",
    "            \"book\": wrong_book,\n",
    "            \"chapter_num\": chapter_num,\n",
    "            \"verse_num\": verse_num\n",
    "        }\n",
    "    right_args = {\n",
    "            \"version\": version,\n",
    "            \"book\": book,\n",
    "            \"chapter_num\": chapter_num,\n",
    "            \"verse_num\": verse_num\n",
    "        }\n",
    "\n",
    "    user_req_variations = get_user_lookup_variations()\n",
    "    variation1 = int(np.random.choice(len(user_req_variations), 1)[0])\n",
    "    user_msg1 = user_req_variations[variation1].format_map(wrong_args)\n",
    "    llm_msg1 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_LOOKUP_VERSE,\n",
    "        dummy_agent.KEY_ARGS: wrong_args}, ensure_ascii=False)\n",
    "    try:\n",
    "        lookup_result_obj = bblt.lookup_verse(**wrong_args)\n",
    "        print(f\"!!! Suspicious. We expected this trial to fail because of wrong args ({typo_class}) {wrong_args}\")\n",
    "        return None\n",
    "    except Exception as ex:\n",
    "        error_msg = str(ex)\n",
    "\n",
    "    tool_msg1 = json.dumps({\n",
    "        \"tool_name\": tool_name,\n",
    "        \"status\": \"error\",\n",
    "        \"error_message\": error_msg\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "    # Book name is easy. Skip surfacing error to user - the LLM should immediately interpret the error message and initiate another tool call with the right arguments:\n",
    "    llm_msg3 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_LOOKUP_VERSE,\n",
    "        dummy_agent.KEY_ARGS: right_args}, ensure_ascii=False)\n",
    "\n",
    "    try:\n",
    "        lookup_result_obj = bblt.lookup_verse(**right_args)\n",
    "        verse_text = lookup_result_obj[\"text\"]\n",
    "        if not isinstance(verse_text, str):\n",
    "            raise ValueError(\"Verse text must be a string\")\n",
    "    except Exception as ex:\n",
    "        print(f\"!!! Suspicious. We expected this to succeed, but got {str(ex)}\")\n",
    "        return None\n",
    "\n",
    "    tool_resp = json.dumps({\n",
    "        \"tool_name\": tool_name,\n",
    "        \"status\": \"ok\",\n",
    "        \"result\": lookup_result_obj\n",
    "    } ,ensure_ascii=False)\n",
    "    llm_msg4 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_RESPOND_TO_USER,\n",
    "        dummy_agent.KEY_ARGS: {\"text\": verse_text}}, ensure_ascii=False)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": dummy_agent.ROLE_SYSTEM, \"content\": dummy_agent.system_instructions},\n",
    "        {\"role\": dummy_agent.ROLE_USER, \"content\": user_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_TOOL, \"content\": tool_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg3},\n",
    "        {\"role\": dummy_agent.ROLE_TOOL, \"content\": tool_resp},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg4}\n",
    "    ]\n",
    "    metadata = {\n",
    "        \"scenario\": \"lookup_verse_typo_book\",\n",
    "        \"variation1\": variation1,\n",
    "        \"typo_class\": typo_class,\n",
    "        \"wrong_args\": wrong_args,\n",
    "        \"right_args\": right_args\n",
    "    }\n",
    "    example = {\"metadata\": metadata, \"messages\": messages}\n",
    "    return example\n",
    "\n",
    "def synth_lookup_verse_ok(book, version, chapter_num, verse_num):\n",
    "    tool_name = dummy_agent.TOOL_LOOKUP_VERSE\n",
    "    tool_args = {\n",
    "            \"version\": version,\n",
    "            \"book\": book,\n",
    "            \"chapter_num\": chapter_num,\n",
    "            \"verse_num\": verse_num\n",
    "        }\n",
    "    \n",
    "    variations = get_user_lookup_variations()\n",
    "    variation = int(np.random.choice(len(variations), 1)[0])\n",
    "    user_msg = variations[variation].format_map(tool_args)\n",
    "    llm_msg1 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_LOOKUP_VERSE,\n",
    "        dummy_agent.KEY_ARGS: tool_args}, ensure_ascii=False)\n",
    "    try:\n",
    "        lookup_result_obj = bblt.lookup_verse(**tool_args)\n",
    "        verse_text = lookup_result_obj[\"text\"]\n",
    "        if not isinstance(verse_text, str):\n",
    "            raise ValueError(\"Verse text must be a string\")\n",
    "    except Exception as ex:\n",
    "        print(f\"!!! Suspicious. We expected this to succeed, but got {str(ex)}\")\n",
    "        return None\n",
    "\n",
    "    tool_resp = json.dumps({\n",
    "        \"tool_name\": tool_name,\n",
    "        \"status\": \"ok\",\n",
    "        \"result\": lookup_result_obj\n",
    "    } ,ensure_ascii=False)\n",
    "    llm_msg2 = json.dumps({\n",
    "        dummy_agent.KEY_TOOL: dummy_agent.TOOL_RESPOND_TO_USER,\n",
    "        dummy_agent.KEY_ARGS: {\"text\": verse_text}}, ensure_ascii=False)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": dummy_agent.ROLE_SYSTEM, \"content\": dummy_agent.system_instructions},\n",
    "        {\"role\": dummy_agent.ROLE_USER, \"content\": user_msg},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg1},\n",
    "        {\"role\": dummy_agent.ROLE_TOOL, \"content\": tool_resp},\n",
    "        {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": llm_msg2}\n",
    "    ]\n",
    "    metadata = {\n",
    "        \"scenario\": \"lookup_verse_ok\",\n",
    "        \"variation\": variation,\n",
    "        \"args\": tool_args\n",
    "    }\n",
    "    example = {\"metadata\": metadata, \"messages\": messages}\n",
    "    return example\n",
    "\n",
    "def synth_lookup_and_another_version(book, version, chapter_num, verse_num):\n",
    "    other_versions = list(bblt.supported_versions)\n",
    "    other_versions.remove(version)\n",
    "    version2 = random.choice(other_versions)\n",
    "\n",
    "    synth_functions = [\n",
    "        synth_lookup_verse_ok, \n",
    "        synth_lookup_verse_version_typo,\n",
    "        synth_lookup_verse_book_typo,\n",
    "    ]\n",
    "    func1 = random.choice(synth_functions)\n",
    "    func2 = random.choice(synth_functions)\n",
    "    example1 = func1(book, version, chapter_num, verse_num)\n",
    "    if not example1:\n",
    "        return None\n",
    "    example2 = func2(book, version2, chapter_num, verse_num)\n",
    "    if not example2:\n",
    "        return None\n",
    "    segue_phrases = [\n",
    "        f\"Great, now from '{version2}'\",\n",
    "        f\"thnk you. also I want it from {version2}\",\n",
    "        f\"good, I also want another version. {version2}.\",\n",
    "        f\"thx. please now same verse from {version2} version.\",\n",
    "        f\"and from {version2}.\",\n",
    "        f\"good. give me also {chapter_num}:{verse_num} from the '{version2}' version\",\n",
    "        f\"I want also the {version2} translation.\"\n",
    "    ]\n",
    "    seg_variation = int(np.random.choice(len(segue_phrases), 1)[0])\n",
    "    whole_convo = example1[\"messages\"]\n",
    "    whole_convo.append({\"role\": dummy_agent.ROLE_USER, \"content\": segue_phrases[seg_variation]})\n",
    "    whole_convo.extend(example2[\"messages\"][2:]) # skip the system msg and the original first user msg\n",
    "    \n",
    "    metadata = {\n",
    "        \"scenario\": \"lookup_verse_ok_then_another_version\",\n",
    "        \"part1\": example1[\"metadata\"],\n",
    "        \"segue_variation\": seg_variation,\n",
    "        \"part2\": example2[\"metadata\"]\n",
    "    }\n",
    "    example = {\n",
    "        \"metadata\": metadata,\n",
    "        \"messages\": whole_convo\n",
    "    }\n",
    "    return example\n",
    "\n",
    "def synth_chitchat_examples():\n",
    "    pairs = [\n",
    "        (\"Hi there, what can you help me with?\", \"I can assist you with analyzing biblical texts.\"),\n",
    "        (\"Hello\", \"Hi. How can I help you?\"),\n",
    "        (\"how are you doing today?\", \"I am well, thank you.\"),\n",
    "        (\"hi\", \"Hello!\"),\n",
    "        (\"I want your help.\", \"Sure. Let me know how I can assist you.\"),\n",
    "        (\"Hey can you help me?\", \"Sure, I can help you with Biblical texts.\"),\n",
    "        (\"Hello there!\", \"Hello to you. How can I assist you?\"),\n",
    "        (\"How do I ask you for a biblical verse?\", \"Just tell me which biblical book you want, in which version/translation, the chapter number and verse number.\")\n",
    "    ]\n",
    "    examples = [\n",
    "        {\n",
    "            \"messages\":[\n",
    "                {\"role\": dummy_agent.ROLE_SYSTEM, \"content\": dummy_agent.system_instructions},\n",
    "                {\"role\": dummy_agent.ROLE_USER, \"content\": pair[0]},\n",
    "                {\"role\": dummy_agent.ROLE_ASSISTANT, \"content\": pair[1]}\n",
    "            ],\n",
    "            \"metadata\": {\"scenario\": \"chitchat\"}\n",
    "        }\n",
    "        for pair in pairs]\n",
    "    return examples\n",
    "\n",
    "def create_examples():\n",
    "    ratio = 0.05\n",
    "    examples = []\n",
    "    examples.extend(10*synth_chitchat_examples())\n",
    "    synth_functions = [\n",
    "        synth_lookup_verse_ok, \n",
    "        synth_lookup_verse_version_typo,\n",
    "        synth_lookup_verse_book_typo,\n",
    "        synth_lookup_and_another_version\n",
    "        ]\n",
    "    for book in bblt.supported_books:\n",
    "        # Load the whole book just once, then make individual calls to the tool to get authentic tool responses\n",
    "        book_verses = sef.sefaria_read_verses_and_metadata(book, bblt.supported_versions[0], strip_html=True)\n",
    "        book_verse_index = [{'chapter': item['chapter_num'], 'verse': item['verse_num']} for item in book_verses] # keep only verse \"index\"\n",
    "        bn = len(book_verses)\n",
    "        for version in bblt.supported_versions:\n",
    "            print(f\"book '{book}' ({bn} verses), version '{version}'\")\n",
    "            sample_verse_dicts = np.random.choice(book_verse_index, size=int(ratio*bn), replace=False)\n",
    "            for verse_index in sample_verse_dicts:\n",
    "                synth_func = random.choice(synth_functions)\n",
    "                example = synth_func(book, version, verse_index['chapter'], verse_index['verse'])\n",
    "\n",
    "                if example:\n",
    "                    examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7489dd94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book 'genesis' (1533 verses), version 'he.text_only'\n",
      "book 'genesis' (1533 verses), version 'he.masorah'\n",
      "book 'genesis' (1533 verses), version 'en.new.jps1917'\n",
      "book 'genesis' (1533 verses), version 'en.koren'\n",
      "book 'exodus' (1210 verses), version 'he.text_only'\n",
      "book 'exodus' (1210 verses), version 'he.masorah'\n",
      "book 'exodus' (1210 verses), version 'en.new.jps1917'\n",
      "book 'exodus' (1210 verses), version 'en.koren'\n",
      "!!! Suspicious. We expected this trial to fail because of wrong args (nearby_char) {'version': 'he.text_only', 'book': 'exodus', 'chapter_num': 24, 'verse_num': 10}\n",
      "book 'leviticus' (859 verses), version 'he.text_only'\n",
      "book 'leviticus' (859 verses), version 'he.masorah'\n",
      "book 'leviticus' (859 verses), version 'en.new.jps1917'\n",
      "book 'leviticus' (859 verses), version 'en.koren'\n",
      "book 'numbers' (1288 verses), version 'he.text_only'\n",
      "book 'numbers' (1288 verses), version 'he.masorah'\n",
      "book 'numbers' (1288 verses), version 'en.new.jps1917'\n",
      "book 'numbers' (1288 verses), version 'en.koren'\n",
      "book 'deuteronomy' (956 verses), version 'he.text_only'\n",
      "book 'deuteronomy' (956 verses), version 'he.masorah'\n",
      "book 'deuteronomy' (956 verses), version 'en.new.jps1917'\n",
      "book 'deuteronomy' (956 verses), version 'en.koren'\n",
      "book 'isaiah' (1291 verses), version 'he.text_only'\n",
      "book 'isaiah' (1291 verses), version 'he.masorah'\n",
      "book 'isaiah' (1291 verses), version 'en.new.jps1917'\n",
      "book 'isaiah' (1291 verses), version 'en.koren'\n",
      "book 'jeremiah' (1364 verses), version 'he.text_only'\n",
      "book 'jeremiah' (1364 verses), version 'he.masorah'\n",
      "book 'jeremiah' (1364 verses), version 'en.new.jps1917'\n",
      "book 'jeremiah' (1364 verses), version 'en.koren'\n",
      "1763\n"
     ]
    }
   ],
   "source": [
    "examples = create_examples()\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c2f1707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'scenario': 'lookup_verse_typo_book',\n",
       "  'variation1': 7,\n",
       "  'typo_class': 'extra_char_cap',\n",
       "  'wrong_args': {'version': 'he.text_only',\n",
       "   'book': 'Ygenesis',\n",
       "   'chapter_num': 41,\n",
       "   'verse_num': 33},\n",
       "  'right_args': {'version': 'he.text_only',\n",
       "   'book': 'genesis',\n",
       "   'chapter_num': 41,\n",
       "   'verse_num': 33}},\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': 'You are a research assistant that always responds using a JSON object with fields \"tool\" and \"arguments\".\\n\\nTo respond normally to the user, use:\\n{\"tool\": \"respond_to_user\", \"arguments\":{\"text\": \"<text to show the user>\"}}\\n\\nTo call a tool, use:\\n{\"tool\": \"<tool_name>\", \"arguments\":{ ... }}\\n\\nAfter you call a tool, you will receive a message with role \"user\" containing a JSON object.\\nThe tool message always includes \"tool_name\" and \"status\".\\n\\nIf \"status\" is \"ok\":\\n- The message will include a \"result\" object.\\n- Read \"result.text\".\\n- Respond using \"respond_to_user\" and copy \"result.text\" exactly as-is.\\n\\nIf \"status\" is \"error\":\\n- The message will include an \"error_message\".\\n- If the error message is clear enough (e.g., if the user spelled a book name wrong and it is clear which book the user intended), you can call the tool again with the corrected arguments.\\n- Otherwise, respond using \"respond_to_user\" and copy \"error_message\" exactly as-is (to let the user tell you what to do next).\\n\\nRules:\\n- Never modify, translate, summarize, or explain text returned by the tool.\\n- Never add commentary or extra text.\\n- Never guess missing arguments.\\n- Never correct user mistakes on the first attempt of a tool call.\\n- Never retry a failed tool call with exactly the same arguments.\\n\\nAvailable tool:\\n\\nTo get the text of a specific biblical verse:\\n{\"tool\": \"lookup_verse\", \"arguments\":{\"version\":\"<version>\", book:\"<book>\", chapter_num:<integer>, verse_num:<integer>}}\\nWhen this tool call succeeds, contains the verse. Copy it exactly as-is and return to the user with \"respond_to_user\".\\n\\n'},\n",
       "  {'role': 'user',\n",
       "   'content': \"Could you retrieve Ygenesis chapter 41 verse 33 in 'he.text_only'?\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': '{\"tool\": \"lookup_verse\", \"arguments\": {\"version\": \"he.text_only\", \"book\": \"Ygenesis\", \"chapter_num\": 41, \"verse_num\": 33}}'},\n",
       "  {'role': 'user',\n",
       "   'content': '{\"tool_name\": \"lookup_verse\", \"status\": \"error\", \"error_message\": \"We don\\'t support book named \\'ygenesis\\'. Here are the supported books: genesis, exodus, leviticus, numbers, deuteronomy, isaiah, jeremiah\"}'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '{\"tool\": \"lookup_verse\", \"arguments\": {\"version\": \"he.text_only\", \"book\": \"genesis\", \"chapter_num\": 41, \"verse_num\": 33}}'},\n",
       "  {'role': 'user',\n",
       "   'content': '{\"tool_name\": \"lookup_verse\", \"status\": \"ok\", \"result\": {\"version\": \"he.text_only\", \"book\": \"genesis\", \"chapter_num\": 41, \"verse_num\": 33, \"text\": \"ועתה ירא פרעה איש נבון וחכם וישיתהו על ארץ מצרים\"}}'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '{\"tool\": \"respond_to_user\", \"arguments\": {\"text\": \"ועתה ירא פרעה איש נבון וחכם וישיתהו על ארץ מצרים\"}}'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8f46343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chitchat',\n",
       " 'lookup_verse_ok',\n",
       " 'lookup_verse_ok_then_another_version',\n",
       " 'lookup_verse_typo_book',\n",
       " 'lookup_verse_typo_version'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([ex['metadata']['scenario'] for ex in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "128e03ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extra_char', 'genwesis'),\n",
       " ('extra_char', 'genesjis'),\n",
       " ('extra_char_cap', 'Genesias'),\n",
       " ('char_swap_allcaps', 'GENEISS'),\n",
       " ('char_swap_cap', 'Genseis'),\n",
       " ('extra_char_cap', 'Genesuis'),\n",
       " ('missing_char_cap', 'Geesis'),\n",
       " ('missing_char', 'enesis'),\n",
       " ('char_swap_cap', 'Geensis'),\n",
       " ('extra_char', 'gwenesis'),\n",
       " ('missing_char', 'genesi'),\n",
       " ('repeated_char_allcaps', 'GGENESIS'),\n",
       " ('char_swap_allcaps', 'GENSEIS'),\n",
       " ('char_swap_cap', 'Gneesis'),\n",
       " ('repeated_char', 'genessis'),\n",
       " ('missing_char_allcaps', 'GENSIS'),\n",
       " ('char_swap_allcaps', 'GNEESIS'),\n",
       " ('extra_char_allcaps', 'GENEESIS'),\n",
       " ('repeated_char_allcaps', 'GENEESIS'),\n",
       " ('repeated_char', 'geneesis'),\n",
       " ('missing_char_cap', 'Geness'),\n",
       " ('missing_char_cap', 'Genesi'),\n",
       " ('extra_char_cap', 'Vgenesis'),\n",
       " ('nearby_char_cap', 'Genesos'),\n",
       " ('repeated_char', 'genesiis'),\n",
       " ('extra_char_cap', 'Hgenesis'),\n",
       " ('nearby_char', 'genssis'),\n",
       " ('extra_char', 'gwenesis'),\n",
       " ('missing_char', 'gensis'),\n",
       " ('missing_char', 'genesi'),\n",
       " ('nearby_char', 'geneais'),\n",
       " ('extra_char_cap', 'Genesois'),\n",
       " ('repeated_char', 'genesiss'),\n",
       " ('repeated_char_cap', 'Genessis'),\n",
       " ('extra_char_cap', 'Gdenesis'),\n",
       " ('nearby_char_allcaps', 'GEMESIS'),\n",
       " ('extra_char_allcaps', 'GEMNESIS'),\n",
       " ('repeated_char_cap', 'Genessis'),\n",
       " ('char_swap_cap', 'Egnesis'),\n",
       " ('extra_char_allcaps', 'GENEESIS'),\n",
       " ('char_swap_allcaps', 'GENESSI'),\n",
       " ('char_swap_allcaps', 'GENSEIS'),\n",
       " ('missing_char', 'enesis'),\n",
       " ('nearby_char_allcaps', 'GRNESIS'),\n",
       " ('repeated_char', 'ggenesis'),\n",
       " ('nearby_char_cap', 'Geneais'),\n",
       " ('extra_char', 'genezsis'),\n",
       " ('char_swap_allcaps', 'GNEESIS'),\n",
       " ('repeated_char_allcaps', 'GEENESIS'),\n",
       " ('extra_char_cap', 'Genesois'),\n",
       " ('char_swap_cap', 'Genseis'),\n",
       " ('char_swap_allcaps', 'GNEESIS'),\n",
       " ('nearby_char', 'geneais'),\n",
       " ('extra_char_cap', 'Genesias'),\n",
       " ('extra_char', 'gsenesis'),\n",
       " ('repeated_char_allcaps', 'GEENESIS'),\n",
       " ('nearby_char', 'gemesis'),\n",
       " ('nearby_char_cap', 'Yenesis'),\n",
       " ('char_swap_cap', 'Genessi'),\n",
       " ('char_swap', 'genseis'),\n",
       " ('extra_char', 'gejnesis'),\n",
       " ('repeated_char_cap', 'Genesiss'),\n",
       " ('extra_char', 'genesois'),\n",
       " ('nearby_char_cap', 'Gebesis'),\n",
       " ('repeated_char_allcaps', 'GEENESIS'),\n",
       " ('char_swap', 'geneiss'),\n",
       " ('char_swap_cap', 'Egnesis'),\n",
       " ('repeated_char_cap', 'Genesiss'),\n",
       " ('char_swap_cap', 'Geneiss'),\n",
       " ('nearby_char_cap', 'Genrsis'),\n",
       " ('repeated_char_cap', 'Geneesis'),\n",
       " ('char_swap_cap', 'Genessi'),\n",
       " ('missing_char', 'gensis'),\n",
       " ('extra_char_cap', 'Genesuis'),\n",
       " ('repeated_char', 'genesiis'),\n",
       " ('char_swap', 'egnesis'),\n",
       " ('char_swap_cap', 'Egnesis'),\n",
       " ('char_swap', 'genseis'),\n",
       " ('repeated_char', 'geenesis'),\n",
       " ('repeated_char_allcaps', 'GENESSIS'),\n",
       " ('repeated_char_allcaps', 'GENEESIS'),\n",
       " ('nearby_char_allcaps', 'GENESKS'),\n",
       " ('nearby_char_cap', 'Genesix'),\n",
       " ('nearby_char_allcaps', 'GWNESIS'),\n",
       " ('extra_char_cap', 'Gebnesis'),\n",
       " ('extra_char', 'genexsis'),\n",
       " ('nearby_char', 'genesia'),\n",
       " ('missing_char_cap', 'Geness'),\n",
       " ('char_swap', 'geneiss'),\n",
       " ('repeated_char_allcaps', 'GENESISS'),\n",
       " ('char_swap_cap', 'Egnesis'),\n",
       " ('repeated_char_allcaps', 'GGENESIS'),\n",
       " ('char_swap_allcaps', 'GNEESIS'),\n",
       " ('char_swap', 'exodsu'),\n",
       " ('repeated_char', 'exoddus'),\n",
       " ('extra_char_cap', 'Exofdus'),\n",
       " ('repeated_char_allcaps', 'EXODUUS'),\n",
       " ('extra_char_allcaps', 'EXLODUS'),\n",
       " ('nearby_char', 'exofus'),\n",
       " ('missing_char_cap', 'Exods'),\n",
       " ('missing_char', 'exous'),\n",
       " ('extra_char_allcaps', 'EXODIUS'),\n",
       " ('missing_char_cap', 'Exous'),\n",
       " ('missing_char', 'xodus'),\n",
       " ('extra_char_allcaps', 'EXKODUS'),\n",
       " ('missing_char_allcaps', 'EXDUS'),\n",
       " ('missing_char', 'eodus'),\n",
       " ('char_swap', 'eoxdus'),\n",
       " ('missing_char_allcaps', 'EXODS'),\n",
       " ('missing_char_allcaps', 'XODUS'),\n",
       " ('char_swap_allcaps', 'EXODSU'),\n",
       " ('char_swap_cap', 'Exouds'),\n",
       " ('extra_char', 'rexodus'),\n",
       " ('missing_char_cap', 'Eodus'),\n",
       " ('char_swap_cap', 'Exdous'),\n",
       " ('char_swap_allcaps', 'EXOUDS'),\n",
       " ('char_swap', 'exouds'),\n",
       " ('missing_char_cap', 'Xodus'),\n",
       " ('extra_char_allcaps', 'EXODIUS'),\n",
       " ('repeated_char_cap', 'Exxodus'),\n",
       " ('repeated_char', 'eexodus'),\n",
       " ('char_swap_allcaps', 'EXOUDS'),\n",
       " ('extra_char', 'expodus'),\n",
       " ('repeated_char', 'eexodus'),\n",
       " ('missing_char', 'exous'),\n",
       " ('char_swap_allcaps', 'EXOUDS'),\n",
       " ('char_swap_cap', 'Exodsu'),\n",
       " ('missing_char', 'exdus'),\n",
       " ('repeated_char', 'eexodus'),\n",
       " ('repeated_char_allcaps', 'EXODUUS'),\n",
       " ('nearby_char_allcaps', 'EXORUS'),\n",
       " ('extra_char_allcaps', 'EXODYUS'),\n",
       " ('extra_char_cap', 'Expodus'),\n",
       " ('repeated_char', 'exoodus'),\n",
       " ('repeated_char', 'exoodus'),\n",
       " ('repeated_char', 'exoddus'),\n",
       " ('char_swap_cap', 'Xeodus'),\n",
       " ('extra_char', 'exodius'),\n",
       " ('char_swap', 'exodsu'),\n",
       " ('repeated_char_allcaps', 'EEXODUS'),\n",
       " ('nearby_char_cap', 'Exldus'),\n",
       " ('extra_char_allcaps', 'SEXODUS'),\n",
       " ('char_swap', 'eoxdus'),\n",
       " ('char_swap', 'exdous'),\n",
       " ('missing_char_allcaps', 'EXODU'),\n",
       " ('char_swap', 'exouds'),\n",
       " ('char_swap_cap', 'Exodsu'),\n",
       " ('nearby_char', 'wxodus'),\n",
       " ('missing_char_allcaps', 'EXDUS'),\n",
       " ('extra_char_cap', 'Exoduas'),\n",
       " ('nearby_char_allcaps', 'EXODHS'),\n",
       " ('nearby_char_cap', 'Edodus'),\n",
       " ('char_swap_cap', 'Exodsu'),\n",
       " ('repeated_char', 'exxodus'),\n",
       " ('extra_char_allcaps', 'EXODJUS'),\n",
       " ('repeated_char_cap', 'Exxodus'),\n",
       " ('missing_char', 'exods'),\n",
       " ('char_swap_cap', 'Leviitcus'),\n",
       " ('repeated_char_cap', 'Leviticuus'),\n",
       " ('nearby_char_cap', 'Leviticis'),\n",
       " ('nearby_char', 'legiticus'),\n",
       " ('nearby_char_allcaps', 'LEVITIDUS'),\n",
       " ('nearby_char_allcaps', 'LEVIGICUS'),\n",
       " ('missing_char_cap', 'Leviicus'),\n",
       " ('char_swap_allcaps', 'LEVITIUCS'),\n",
       " ('extra_char_cap', 'Oleviticus'),\n",
       " ('nearby_char_allcaps', 'LWVITICUS'),\n",
       " ('extra_char_allcaps', 'LEVITKICUS'),\n",
       " ('repeated_char', 'leviiticus'),\n",
       " ('char_swap_allcaps', 'LEVTIICUS'),\n",
       " ('repeated_char', 'leviticuus'),\n",
       " ('missing_char_allcaps', 'LEVIICUS'),\n",
       " ('nearby_char', 'levitkcus'),\n",
       " ('missing_char_cap', 'Levitcus'),\n",
       " ('repeated_char_allcaps', 'LEVIITICUS'),\n",
       " ('char_swap_cap', 'Lveiticus'),\n",
       " ('char_swap_cap', 'Levitiucs'),\n",
       " ('repeated_char_cap', 'Levviticus'),\n",
       " ('missing_char_allcaps', 'LEVIICUS'),\n",
       " ('nearby_char_cap', 'Leviticuw'),\n",
       " ('repeated_char_allcaps', 'LLEVITICUS'),\n",
       " ('extra_char_cap', 'Levoiticus'),\n",
       " ('missing_char_allcaps', 'LEITICUS'),\n",
       " ('missing_char_allcaps', 'LVITICUS'),\n",
       " ('missing_char', 'levitics'),\n",
       " ('repeated_char_allcaps', 'LLEVITICUS'),\n",
       " ('char_swap', 'levtiicus'),\n",
       " ('extra_char', 'kleviticus'),\n",
       " ('char_swap', 'elviticus'),\n",
       " ('nearby_char', 'levitichs'),\n",
       " ('repeated_char', 'leviiticus'),\n",
       " ('extra_char', 'levitidcus'),\n",
       " ('nearby_char_cap', 'Levkticus'),\n",
       " ('extra_char', 'ldeviticus'),\n",
       " ('repeated_char', 'levitticus'),\n",
       " ('missing_char_cap', 'Levitics'),\n",
       " ('extra_char', 'levitjicus'),\n",
       " ('char_swap_cap', 'Levitiucs'),\n",
       " ('extra_char_cap', 'Levitkicus'),\n",
       " ('nearby_char', 'legiticus'),\n",
       " ('char_swap', 'leivticus'),\n",
       " ('missing_char', 'levitius'),\n",
       " ('extra_char', 'leviyticus'),\n",
       " ('char_swap_cap', 'Elviticus'),\n",
       " ('extra_char_allcaps', 'LEVITKICUS'),\n",
       " ('char_swap_cap', 'Levtiicus'),\n",
       " ('nearby_char', 'levitichs'),\n",
       " ('extra_char_allcaps', 'LEVITICIUS'),\n",
       " ('repeated_char_cap', 'Levviticus'),\n",
       " ('nearby_char', 'levitifus'),\n",
       " ('extra_char_allcaps', 'MNUMBERS'),\n",
       " ('repeated_char', 'nnumbers'),\n",
       " ('nearby_char', 'numbees'),\n",
       " ('char_swap', 'nubmers'),\n",
       " ('char_swap', 'numebrs'),\n",
       " ('missing_char_allcaps', 'NMBERS'),\n",
       " ('nearby_char_allcaps', 'NJMBERS'),\n",
       " ('char_swap_cap', 'Numbesr'),\n",
       " ('repeated_char', 'nummbers'),\n",
       " ('char_swap_cap', 'Numebrs'),\n",
       " ('missing_char_cap', 'Nmbers'),\n",
       " ('repeated_char_cap', 'Numbeers'),\n",
       " ('missing_char', 'numbrs'),\n",
       " ('extra_char_cap', 'Numberas'),\n",
       " ('extra_char_cap', 'Numbefrs'),\n",
       " ('extra_char_cap', 'Numberas'),\n",
       " ('char_swap_cap', 'Nmubers'),\n",
       " ('extra_char_cap', 'Numbders'),\n",
       " ('missing_char_allcaps', 'NUMERS'),\n",
       " ('nearby_char', 'numbere'),\n",
       " ('repeated_char', 'nummbers'),\n",
       " ('char_swap_cap', 'Numebrs'),\n",
       " ('nearby_char_allcaps', 'NJMBERS'),\n",
       " ('nearby_char_allcaps', 'NUJBERS'),\n",
       " ('missing_char_cap', 'Numbrs'),\n",
       " ('char_swap', 'nmubers'),\n",
       " ('char_swap_cap', 'Nubmers'),\n",
       " ('char_swap', 'numebrs'),\n",
       " ('missing_char_allcaps', 'NUMBRS'),\n",
       " ('extra_char_cap', 'Numbeers'),\n",
       " ('repeated_char_cap', 'Numberss'),\n",
       " ('nearby_char_allcaps', 'NUMBWRS'),\n",
       " ('nearby_char_allcaps', 'NUMBDRS'),\n",
       " ('repeated_char', 'numberss'),\n",
       " ('repeated_char_allcaps', 'NUMBERRS'),\n",
       " ('extra_char_allcaps', 'NHUMBERS'),\n",
       " ('char_swap_allcaps', 'NUMEBRS'),\n",
       " ('nearby_char_allcaps', 'NUNBERS'),\n",
       " ('missing_char', 'number'),\n",
       " ('extra_char_cap', 'Nukmbers'),\n",
       " ('extra_char', 'numbrers'),\n",
       " ('char_swap_cap', 'Numbesr'),\n",
       " ('nearby_char', 'numbwrs'),\n",
       " ('char_swap', 'unmbers'),\n",
       " ('missing_char_cap', 'Nubers'),\n",
       " ('extra_char', 'numhbers'),\n",
       " ('missing_char_allcaps', 'NUBERS'),\n",
       " ('repeated_char_allcaps', 'NNUMBERS'),\n",
       " ('repeated_char_allcaps', 'NUMBBERS'),\n",
       " ('nearby_char_cap', 'Numbeds'),\n",
       " ('char_swap_cap', 'Unmbers'),\n",
       " ('repeated_char_allcaps', 'NUMBERSS'),\n",
       " ('nearby_char', 'nunbers'),\n",
       " ('extra_char_allcaps', 'NUMNBERS'),\n",
       " ('char_swap_cap', 'Nmubers'),\n",
       " ('repeated_char', 'nnumbers'),\n",
       " ('extra_char', 'numbetrs'),\n",
       " ('char_swap_cap', 'Numbesr'),\n",
       " ('extra_char_cap', 'Numbefrs'),\n",
       " ('char_swap_cap', 'Numbres'),\n",
       " ('repeated_char_cap', 'Nuumbers'),\n",
       " ('char_swap', 'nmubers'),\n",
       " ('char_swap_cap', 'Numbesr'),\n",
       " ('repeated_char_cap', 'Nummbers'),\n",
       " ('extra_char', 'numbwers'),\n",
       " ('nearby_char_allcaps', 'HUMBERS'),\n",
       " ('char_swap', 'numbres'),\n",
       " ('missing_char_allcaps', 'NUMBRS'),\n",
       " ('missing_char_cap', 'Numers'),\n",
       " ('nearby_char_allcaps', 'NUMBEDS'),\n",
       " ('extra_char_cap', 'Numbetrs'),\n",
       " ('char_swap_cap', 'Numbesr'),\n",
       " ('char_swap_allcaps', 'NUMBESR'),\n",
       " ('missing_char_cap', 'Nmbers'),\n",
       " ('extra_char_cap', 'Nujmbers'),\n",
       " ('missing_char', 'nmbers'),\n",
       " ('extra_char', 'nhumbers'),\n",
       " ('nearby_char_cap', 'Njmbers'),\n",
       " ('missing_char_cap', 'Numbes'),\n",
       " ('char_swap_cap', 'Numebrs'),\n",
       " ('char_swap_allcaps', 'UNMBERS'),\n",
       " ('missing_char', 'number'),\n",
       " ('extra_char_allcaps', 'DEUGTERONOMY'),\n",
       " ('extra_char_cap', 'Deutefronomy'),\n",
       " ('extra_char_cap', 'Sdeuteronomy'),\n",
       " ('nearby_char', 'deuterobomy'),\n",
       " ('missing_char_allcaps', 'DEUTRONOMY'),\n",
       " ('nearby_char_allcaps', 'DEYTERONOMY'),\n",
       " ('char_swap_allcaps', 'DEUTERONMOY'),\n",
       " ('missing_char_allcaps', 'DEUTEONOMY'),\n",
       " ('nearby_char_cap', 'Deuteronomg'),\n",
       " ('extra_char_cap', 'Deugteronomy'),\n",
       " ('extra_char_allcaps', 'DEJUTERONOMY'),\n",
       " ('extra_char_allcaps', 'DEUTEROBNOMY'),\n",
       " ('missing_char', 'deteronomy'),\n",
       " ('missing_char_cap', 'Deuteroomy'),\n",
       " ('nearby_char_allcaps', 'DEUTERLNOMY'),\n",
       " ('missing_char_cap', 'Deuteronoy'),\n",
       " ('missing_char_allcaps', 'DEUERONOMY'),\n",
       " ('nearby_char', 'deuteromomy'),\n",
       " ('missing_char', 'euteronomy'),\n",
       " ('missing_char', 'duteronomy'),\n",
       " ('char_swap', 'deuteronoym'),\n",
       " ('missing_char_cap', 'Euteronomy'),\n",
       " ('char_swap', 'deuteroonmy'),\n",
       " ('nearby_char_allcaps', 'DEYTERONOMY'),\n",
       " ('extra_char', 'deuterkonomy'),\n",
       " ('nearby_char_allcaps', 'DEUYERONOMY'),\n",
       " ('extra_char_allcaps', 'DEUTERONOJMY'),\n",
       " ('repeated_char_cap', 'Deuuteronomy'),\n",
       " ('char_swap_allcaps', 'DEUETRONOMY'),\n",
       " ('nearby_char_allcaps', 'DEUTEFONOMY'),\n",
       " ('extra_char_allcaps', 'DEUTEERONOMY'),\n",
       " ('extra_char_cap', 'Deuteronomgy'),\n",
       " ('extra_char', 'deutedronomy'),\n",
       " ('repeated_char', 'deutteronomy'),\n",
       " ('extra_char', 'deuteronomty'),\n",
       " ('char_swap_cap', 'Deuternoomy'),\n",
       " ('char_swap', 'deuteronoym'),\n",
       " ('extra_char', 'dweuteronomy'),\n",
       " ('repeated_char_allcaps', 'DEUTEERONOMY'),\n",
       " ('nearby_char', 'dduteronomy'),\n",
       " ('nearby_char_cap', 'Dejteronomy'),\n",
       " ('nearby_char_allcaps', 'DEUTWRONOMY'),\n",
       " ('extra_char_cap', 'Rdeuteronomy'),\n",
       " ('extra_char_allcaps', 'DEUTEERONOMY'),\n",
       " ('extra_char_allcaps', 'EDEUTERONOMY'),\n",
       " ('repeated_char', 'deeuteronomy'),\n",
       " ('nearby_char_cap', 'Deuterohomy'),\n",
       " ('nearby_char', 'deuteronoky'),\n",
       " ('char_swap_allcaps', 'EDUTERONOMY'),\n",
       " ('repeated_char_allcaps', 'DEUTERONNOMY'),\n",
       " ('nearby_char', 'deuteromomy'),\n",
       " ('extra_char_allcaps', 'DEUTERONKOMY'),\n",
       " ('repeated_char', 'ddeuteronomy'),\n",
       " ('char_swap_cap', 'Deutreonomy'),\n",
       " ('missing_char_allcaps', 'DEUERONOMY'),\n",
       " ('missing_char_allcaps', 'DUTERONOMY'),\n",
       " ('char_swap_cap', 'Deutreonomy'),\n",
       " ('char_swap', 'deuteroonmy'),\n",
       " ('char_swap_allcaps', 'DEUETRONOMY'),\n",
       " ('repeated_char_allcaps', 'DEUTERONNOMY'),\n",
       " ('nearby_char', 'xeuteronomy'),\n",
       " ('nearby_char_allcaps', 'DEUFERONOMY'),\n",
       " ('missing_char_allcaps', 'DETERONOMY'),\n",
       " ('char_swap', 'deuteronoym'),\n",
       " ('missing_char', 'deuteroomy'),\n",
       " ('repeated_char_cap', 'Deuteeronomy'),\n",
       " ('extra_char_cap', 'Deurteronomy'),\n",
       " ('missing_char', 'deuteroomy'),\n",
       " ('nearby_char_allcaps', 'DEITERONOMY'),\n",
       " ('nearby_char_cap', 'Deutdronomy'),\n",
       " ('repeated_char', 'iisaiah'),\n",
       " ('repeated_char_allcaps', 'ISAIAHH'),\n",
       " ('extra_char', 'isaiwah'),\n",
       " ('extra_char', 'isaisah'),\n",
       " ('missing_char_cap', 'Isaih'),\n",
       " ('missing_char_allcaps', 'IAIAH'),\n",
       " ('missing_char', 'isaah'),\n",
       " ('nearby_char_allcaps', 'ISAUAH'),\n",
       " ('char_swap_cap', 'Isaiha'),\n",
       " ('repeated_char_cap', 'Isaiaah'),\n",
       " ('repeated_char_allcaps', 'ISAIAHH'),\n",
       " ('missing_char', 'isaah'),\n",
       " ('char_swap_allcaps', 'ISAIHA'),\n",
       " ('missing_char', 'isaih'),\n",
       " ('char_swap_allcaps', 'IASIAH'),\n",
       " ('extra_char_allcaps', 'KISAIAH'),\n",
       " ('char_swap', 'siaiah'),\n",
       " ('missing_char', 'isaih'),\n",
       " ('repeated_char_cap', 'Issaiah'),\n",
       " ('missing_char_cap', 'Isaih'),\n",
       " ('missing_char', 'isaia'),\n",
       " ('extra_char', 'isqaiah'),\n",
       " ('missing_char_cap', 'Isaah'),\n",
       " ('nearby_char', 'izaiah'),\n",
       " ('char_swap_allcaps', 'SIAIAH'),\n",
       " ('nearby_char', 'isajah'),\n",
       " ('repeated_char_allcaps', 'IISAIAH'),\n",
       " ('extra_char', 'iswaiah'),\n",
       " ('missing_char', 'isiah'),\n",
       " ('char_swap_allcaps', 'IASIAH'),\n",
       " ('extra_char', 'isakiah'),\n",
       " ('repeated_char_allcaps', 'ISAIAHH'),\n",
       " ('extra_char', 'isakiah'),\n",
       " ('repeated_char_allcaps', 'IISAIAH'),\n",
       " ('repeated_char_cap', 'Isaaiah'),\n",
       " ('missing_char', 'iaiah'),\n",
       " ('extra_char_cap', 'Uisaiah'),\n",
       " ('repeated_char', 'isaiahh'),\n",
       " ('char_swap_allcaps', 'ISAIHA'),\n",
       " ('nearby_char_cap', 'Isauah'),\n",
       " ('missing_char_allcaps', 'SAIAH'),\n",
       " ('missing_char_allcaps', 'IAIAH'),\n",
       " ('repeated_char', 'isaaiah'),\n",
       " ('repeated_char_allcaps', 'ISAIAAH'),\n",
       " ('repeated_char_cap', 'Issaiah'),\n",
       " ('char_swap_allcaps', 'SIAIAH'),\n",
       " ('char_swap_allcaps', 'ISAIHA'),\n",
       " ('extra_char', 'isakiah'),\n",
       " ('missing_char_allcaps', 'ISAAH'),\n",
       " ('repeated_char', 'isaiiah'),\n",
       " ('repeated_char_cap', 'Isaaiah'),\n",
       " ('extra_char_cap', 'Issaiah'),\n",
       " ('char_swap_allcaps', 'IASIAH'),\n",
       " ('nearby_char_allcaps', 'IWAIAH'),\n",
       " ('extra_char_cap', 'Uisaiah'),\n",
       " ('char_swap_cap', 'Iasiah'),\n",
       " ('extra_char_cap', 'Iesaiah'),\n",
       " ('char_swap_cap', 'Siaiah'),\n",
       " ('repeated_char_allcaps', 'ISAIAAH'),\n",
       " ('repeated_char', 'issaiah'),\n",
       " ('char_swap_cap', 'Iasiah'),\n",
       " ('repeated_char_cap', 'Isaaiah'),\n",
       " ('repeated_char', 'issaiah'),\n",
       " ('extra_char_allcaps', 'IWSAIAH'),\n",
       " ('nearby_char', 'usaiah'),\n",
       " ('missing_char', 'iaiah'),\n",
       " ('repeated_char_allcaps', 'ISAIAHH'),\n",
       " ('extra_char_cap', 'Ixsaiah'),\n",
       " ('repeated_char', 'isaaiah'),\n",
       " ('char_swap_cap', 'Isaiha'),\n",
       " ('extra_char_allcaps', 'ISAIANH'),\n",
       " ('repeated_char_cap', 'Isaiaah'),\n",
       " ('repeated_char_allcaps', 'ISAIIAH'),\n",
       " ('extra_char_allcaps', 'ISSAIAH'),\n",
       " ('extra_char', 'iwsaiah'),\n",
       " ('extra_char_cap', 'Isaianh'),\n",
       " ('repeated_char_cap', 'Isaaiah'),\n",
       " ('extra_char_allcaps', 'IDSAIAH'),\n",
       " ('nearby_char_cap', 'Isaian'),\n",
       " ('missing_char_allcaps', 'ISAIH'),\n",
       " ('repeated_char_allcaps', 'ISAAIAH'),\n",
       " ('repeated_char', 'isaaiah'),\n",
       " ('repeated_char_cap', 'Isaaiah'),\n",
       " ('char_swap_cap', 'Iasiah'),\n",
       " ('missing_char_cap', 'Isaah'),\n",
       " ('nearby_char_cap', 'Isaiqh'),\n",
       " ('missing_char', 'saiah'),\n",
       " ('missing_char_allcaps', 'SAIAH'),\n",
       " ('extra_char_allcaps', 'ISWAIAH'),\n",
       " ('repeated_char_allcaps', 'ISAIIAH'),\n",
       " ('missing_char_allcaps', 'SAIAH'),\n",
       " ('char_swap_cap', 'Siaiah'),\n",
       " ('extra_char_cap', 'Isaoiah'),\n",
       " ('char_swap_cap', 'Siaiah'),\n",
       " ('missing_char_allcaps', 'ISAAH'),\n",
       " ('missing_char_cap', 'Isaia'),\n",
       " ('nearby_char_allcaps', 'USAIAH'),\n",
       " ('missing_char', 'isaih'),\n",
       " ('nearby_char_allcaps', 'JERDMIAH'),\n",
       " ('missing_char_allcaps', 'JEREMAH'),\n",
       " ('missing_char', 'eremiah'),\n",
       " ('extra_char_cap', 'Jedremiah'),\n",
       " ('char_swap_cap', 'Jreemiah'),\n",
       " ('char_swap_cap', 'Jreemiah'),\n",
       " ('char_swap_cap', 'Jeremaih'),\n",
       " ('missing_char_cap', 'Jereiah'),\n",
       " ('nearby_char', 'jrremiah'),\n",
       " ('repeated_char', 'jeremiiah'),\n",
       " ('char_swap', 'jereimah'),\n",
       " ('missing_char_allcaps', 'JREMIAH'),\n",
       " ('missing_char_allcaps', 'JEREMIH'),\n",
       " ('extra_char', 'jetremiah'),\n",
       " ('extra_char_allcaps', 'JEEREMIAH'),\n",
       " ('nearby_char_allcaps', 'JEREMKAH'),\n",
       " ('nearby_char', 'heremiah'),\n",
       " ('nearby_char_cap', 'Jeremkah'),\n",
       " ('char_swap_allcaps', 'EJREMIAH'),\n",
       " ('char_swap_allcaps', 'JEERMIAH'),\n",
       " ('repeated_char_cap', 'Jjeremiah'),\n",
       " ('char_swap_cap', 'Jereimah'),\n",
       " ('missing_char', 'eremiah'),\n",
       " ('char_swap_allcaps', 'JEREMIHA'),\n",
       " ('missing_char_cap', 'Jremiah'),\n",
       " ('missing_char_allcaps', 'JEREIAH'),\n",
       " ('char_swap_cap', 'Ejremiah'),\n",
       " ('repeated_char_cap', 'Jeremiaah'),\n",
       " ('missing_char_cap', 'Jeemiah'),\n",
       " ('nearby_char', 'jeremiay'),\n",
       " ('char_swap_allcaps', 'JEREMAIH'),\n",
       " ('extra_char_cap', 'Ijeremiah'),\n",
       " ('extra_char', 'jeremiayh'),\n",
       " ('char_swap_allcaps', 'EJREMIAH'),\n",
       " ('char_swap_allcaps', 'JEREMIHA'),\n",
       " ('char_swap_allcaps', 'EJREMIAH'),\n",
       " ('extra_char_cap', 'Jeremiajh'),\n",
       " ('extra_char_cap', 'Jeremianh'),\n",
       " ('char_swap_cap', 'Jreemiah'),\n",
       " ('nearby_char_allcaps', 'JEREMISH'),\n",
       " ('repeated_char_cap', 'Jeremiaah'),\n",
       " ('extra_char', 'jreremiah'),\n",
       " ('extra_char_allcaps', 'JEREMIQAH'),\n",
       " ('char_swap_allcaps', 'JERMEIAH'),\n",
       " ('repeated_char_allcaps', 'JEREMIAHH'),\n",
       " ('missing_char', 'jeremia'),\n",
       " ('nearby_char_cap', 'Jeremiqh'),\n",
       " ('extra_char_allcaps', 'JSEREMIAH'),\n",
       " ('repeated_char_cap', 'Jereemiah'),\n",
       " ('char_swap', 'jermeiah'),\n",
       " ('extra_char_allcaps', 'JEEREMIAH'),\n",
       " ('missing_char_allcaps', 'EREMIAH'),\n",
       " ('char_swap', 'jeremaih'),\n",
       " ('char_swap_allcaps', 'JEREMIHA'),\n",
       " ('missing_char', 'jereiah'),\n",
       " ('nearby_char_cap', 'Jwremiah'),\n",
       " ('nearby_char_cap', 'Jeremiab'),\n",
       " ('char_swap', 'jereimah'),\n",
       " ('missing_char_allcaps', 'JEREMIA'),\n",
       " ('repeated_char_allcaps', 'JEEREMIAH'),\n",
       " ('extra_char_cap', 'Jeremjiah'),\n",
       " ('missing_char', 'jermiah'),\n",
       " ('nearby_char', 'jeremkah'),\n",
       " ('nearby_char_cap', 'Jeremiab'),\n",
       " ('extra_char', 'jweremiah'),\n",
       " ('repeated_char', 'jeremiahh'),\n",
       " ('repeated_char_cap', 'Jereemiah'),\n",
       " ('repeated_char_allcaps', 'JEEREMIAH'),\n",
       " ('char_swap', 'ejremiah'),\n",
       " ('repeated_char_cap', 'Jeremmiah'),\n",
       " ('repeated_char', 'jerremiah'),\n",
       " ('extra_char_allcaps', 'HJEREMIAH'),\n",
       " ('missing_char', 'jeremih'),\n",
       " ('char_swap_cap', 'Jeremaih'),\n",
       " ('missing_char', 'eremiah'),\n",
       " ('char_swap', 'jeermiah'),\n",
       " ('extra_char_allcaps', 'JSEREMIAH'),\n",
       " ('char_swap_cap', 'Jeremaih'),\n",
       " ('repeated_char_cap', 'Jereemiah'),\n",
       " ('char_swap_allcaps', 'JREEMIAH'),\n",
       " ('missing_char_allcaps', 'JEREMAH'),\n",
       " ('missing_char', 'jeremah'),\n",
       " ('char_swap_cap', 'Jeermiah'),\n",
       " ('extra_char_cap', 'Jeremizah'),\n",
       " ('repeated_char_allcaps', 'JEEREMIAH'),\n",
       " ('nearby_char_cap', 'Jeremjah'),\n",
       " ('extra_char_cap', 'Jreremiah'),\n",
       " ('char_swap_allcaps', 'JEREMAIH'),\n",
       " ('repeated_char', 'jeremiaah'),\n",
       " ('missing_char', 'jremiah'),\n",
       " ('missing_char_allcaps', 'JEREMIA'),\n",
       " ('repeated_char', 'jeremiahh'),\n",
       " ('nearby_char', 'jeremiaj'),\n",
       " ('char_swap_cap', 'Jreemiah')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ex['metadata']['typo_class'],ex['metadata']['wrong_args']['book']) for ex in examples if ex['metadata']['scenario']=='lookup_verse_typo_book']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b068c9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('char_swap', 'he.txet_only'),\n",
       " ('extra_char', 'he.text_ohnly'),\n",
       " ('extra_char', 'jhe.text_only'),\n",
       " ('char_swap', 'he.text_olny'),\n",
       " ('extra_char', 'he.text_ponly'),\n",
       " ('missing_char', 'he.text_ony'),\n",
       " ('repeated_char', 'he.text_oonly'),\n",
       " ('nearby_char', 'he.text_onoy'),\n",
       " ('nearby_char', 'he.text_inly'),\n",
       " ('extra_char', 'he.text_onkly'),\n",
       " ('nearby_char', 'he.trxt_only'),\n",
       " ('extra_char', 'he.text_konly'),\n",
       " ('missing_char', 'he.tet_only'),\n",
       " ('extra_char', 'he.trext_only'),\n",
       " ('extra_char', 'he.tezxt_only'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('char_swap', 'he.text_noly'),\n",
       " ('extra_char', 'he.text_onlty'),\n",
       " ('repeated_char', 'he.text_onnly'),\n",
       " ('char_swap', 'he.txet_only'),\n",
       " ('missing_char', 'e.text_only'),\n",
       " ('char_swap', 'he.text_noly'),\n",
       " ('missing_char', 'he.tet_only'),\n",
       " ('extra_char', 'he.text__only'),\n",
       " ('repeated_char', 'he.text__only'),\n",
       " ('missing_char', 'he.text_onl'),\n",
       " ('repeated_char', 'he.text__only'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('extra_char', 'he.text_onlty'),\n",
       " ('repeated_char', 'he.masorahh'),\n",
       " ('repeated_char', 'he.maasorah'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('extra_char', 'he.masotrah'),\n",
       " ('repeated_char', 'he.masorahh'),\n",
       " ('repeated_char', 'hee.masorah'),\n",
       " ('nearby_char', 'he.masoray'),\n",
       " ('extra_char', 'he.masodrah'),\n",
       " ('repeated_char', 'hhe.masorah'),\n",
       " ('missing_char', 'e.masorah'),\n",
       " ('repeated_char', 'he.mmasorah'),\n",
       " ('extra_char', 'he.mqasorah'),\n",
       " ('missing_char', 'he.masorh'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('nearby_char', 'he.kasorah'),\n",
       " ('missing_char', 'h.masorah'),\n",
       " ('nearby_char', 'ue.masorah'),\n",
       " ('nearby_char', 'he.maxorah'),\n",
       " ('nearby_char', 'he.mqsorah'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('repeated_char', 'he.masoorah'),\n",
       " ('nearby_char', 'he.maskrah'),\n",
       " ('repeated_char', 'he.masorrah'),\n",
       " ('nearby_char', 'he.mssorah'),\n",
       " ('missing_char', 'en.new.js1917'),\n",
       " ('nearby_char', 'eh.new.jps1917'),\n",
       " ('nearby_char', 'en.new.jps1947'),\n",
       " ('extra_char', 'en.new.jps110917'),\n",
       " ('missing_char', 'en.new.jps197'),\n",
       " ('nearby_char', 'en.nsw.jps1917'),\n",
       " ('nearby_char', 'en.nea.jps1917'),\n",
       " ('char_swap', 'en.new.jp1s917'),\n",
       " ('repeated_char', 'en.new.jpss1917'),\n",
       " ('nearby_char', 'en.new.jps1927'),\n",
       " ('char_swap', 'en.new.jps9117'),\n",
       " ('extra_char', 'en.nrew.jps1917'),\n",
       " ('repeated_char', 'en.new.jps19917'),\n",
       " ('nearby_char', 'en.new.jps11017'),\n",
       " ('char_swap', 'en.new.jps1971'),\n",
       " ('char_swap', 'en.new.jp1s917'),\n",
       " ('missing_char', 'en.new.js1917'),\n",
       " ('char_swap', 'en.nwe.jps1917'),\n",
       " ('missing_char', 'en.new.jps117'),\n",
       " ('missing_char', 'en.nw.jps1917'),\n",
       " ('char_swap', 'ne.new.jps1917'),\n",
       " ('nearby_char', 'en.new.hps1917'),\n",
       " ('char_swap', 'en.new.jps1971'),\n",
       " ('missing_char', 'en.ne.jps1917'),\n",
       " ('nearby_char', 'en.new.jpw1917'),\n",
       " ('extra_char', 'en.nrew.jps1917'),\n",
       " ('nearby_char', 'wn.new.jps1917'),\n",
       " ('nearby_char', 'eb.koren'),\n",
       " ('nearby_char', 'en.koreh'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('nearby_char', 'en.korwn'),\n",
       " ('extra_char', 'ren.koren'),\n",
       " ('repeated_char', 'en.korenn'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('nearby_char', 'sn.koren'),\n",
       " ('missing_char', 'en.kren'),\n",
       " ('nearby_char', 'en.ioren'),\n",
       " ('repeated_char', 'en.kooren'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('extra_char', 'en.kporen'),\n",
       " ('char_swap', 'en.okren'),\n",
       " ('nearby_char', 'en.koreb'),\n",
       " ('nearby_char', 'en.korem'),\n",
       " ('repeated_char', 'en.koreen'),\n",
       " ('repeated_char', 'een.koren'),\n",
       " ('char_swap', 'en.okren'),\n",
       " ('nearby_char', 'en.moren'),\n",
       " ('missing_char', 'e.koren'),\n",
       " ('extra_char', 'ejn.koren'),\n",
       " ('nearby_char', 'wn.koren'),\n",
       " ('extra_char', 'en.kporen'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('nearby_char', 'he.yext_only'),\n",
       " ('extra_char', 'he.texyt_only'),\n",
       " ('nearby_char', 'he.text_obly'),\n",
       " ('missing_char', 'he.textonly'),\n",
       " ('extra_char', 'he.text_onlhy'),\n",
       " ('missing_char', 'he.tex_only'),\n",
       " ('nearby_char', 'he.tedt_only'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('missing_char', 'he.text_ony'),\n",
       " ('char_swap', 'he.text_onyl'),\n",
       " ('extra_char', 'he.text_obnly'),\n",
       " ('repeated_char', 'he.text_onnly'),\n",
       " ('nearby_char', 'he.text_obly'),\n",
       " ('extra_char', 'he.text_onkly'),\n",
       " ('repeated_char', 'hee.text_only'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('char_swap', 'he.text_olny'),\n",
       " ('repeated_char', 'hhe.text_only'),\n",
       " ('repeated_char', 'he.text_onlyy'),\n",
       " ('missing_char', 'he.text_nly'),\n",
       " ('char_swap', 'he.text_noly'),\n",
       " ('char_swap', 'eh.text_only'),\n",
       " ('extra_char', 'yhe.text_only'),\n",
       " ('repeated_char', 'he.teext_only'),\n",
       " ('char_swap', 'he.tetx_only'),\n",
       " ('extra_char', 'he.texgt_only'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('nearby_char', 'he.kasorah'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('missing_char', 'h.masorah'),\n",
       " ('nearby_char', 'he.jasorah'),\n",
       " ('nearby_char', 'ue.masorah'),\n",
       " ('missing_char', 'he.masorh'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('missing_char', 'e.masorah'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('nearby_char', 'he.masorag'),\n",
       " ('extra_char', 'he.maesorah'),\n",
       " ('nearby_char', 'he.masirah'),\n",
       " ('extra_char', 'he.mawsorah'),\n",
       " ('nearby_char', 'he.mssorah'),\n",
       " ('nearby_char', 'he.masorzh'),\n",
       " ('missing_char', 'he.masoah'),\n",
       " ('char_swap', 'en.new.jps1971'),\n",
       " ('repeated_char', 'een.new.jps1917'),\n",
       " ('nearby_char', 'en.new.jos1917'),\n",
       " ('missing_char', 'e.new.jps1917'),\n",
       " ('repeated_char', 'en.new.jps19177'),\n",
       " ('extra_char', 'den.new.jps1917'),\n",
       " ('repeated_char', 'en.new.jpps1917'),\n",
       " ('missing_char', 'en.new.js1917'),\n",
       " ('char_swap', 'en.new.jps1197'),\n",
       " ('nearby_char', 'eh.new.jps1917'),\n",
       " ('char_swap', 'en.enw.jps1917'),\n",
       " ('char_swap', 'en.new.jsp1917'),\n",
       " ('char_swap', 'en.new.pjs1917'),\n",
       " ('missing_char', 'en.nw.jps1917'),\n",
       " ('extra_char', 'en.nsew.jps1917'),\n",
       " ('nearby_char', 'en.new.jps1817'),\n",
       " ('extra_char', 'en.new.jps16917'),\n",
       " ('nearby_char', 'en.new.jos1917'),\n",
       " ('nearby_char', 'wn.new.jps1917'),\n",
       " ('missing_char', 'en.new.jp1917'),\n",
       " ('repeated_char', 'en.new.jps11917'),\n",
       " ('nearby_char', 'eh.koren'),\n",
       " ('missing_char', 'en.koen'),\n",
       " ('extra_char', 'en.kporen'),\n",
       " ('extra_char', 'en.kofren'),\n",
       " ('extra_char', 'en.koremn'),\n",
       " ('missing_char', 'en.koen'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('repeated_char', 'en.korenn'),\n",
       " ('missing_char', 'en.kren'),\n",
       " ('extra_char', 'wen.koren'),\n",
       " ('repeated_char', 'en.kkoren'),\n",
       " ('nearby_char', 'en.koden'),\n",
       " ('extra_char', 'en.koeren'),\n",
       " ('repeated_char', 'en.korren'),\n",
       " ('nearby_char', 'eb.koren'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('repeated_char', 'en.korren'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('char_swap', 'en.okren'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('missing_char', 'he.txt_only'),\n",
       " ('missing_char', 'he.txt_only'),\n",
       " ('repeated_char', 'he.ttext_only'),\n",
       " ('char_swap', 'he.txet_only'),\n",
       " ('repeated_char', 'he.texxt_only'),\n",
       " ('nearby_char', 'he.tezt_only'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('extra_char', 'he.text_omnly'),\n",
       " ('repeated_char', 'he.textt_only'),\n",
       " ('missing_char', 'he.text_nly'),\n",
       " ('missing_char', 'he.txt_only'),\n",
       " ('nearby_char', 'he.text_onlt'),\n",
       " ('repeated_char', 'he.textt_only'),\n",
       " ('missing_char', 'he.text_ony'),\n",
       " ('repeated_char', 'hhe.text_only'),\n",
       " ('char_swap', 'he.tex_tonly'),\n",
       " ('nearby_char', 'he.masoray'),\n",
       " ('char_swap', 'he.msaorah'),\n",
       " ('nearby_char', 'be.masorah'),\n",
       " ('missing_char', 'he.asorah'),\n",
       " ('extra_char', 'he.mqasorah'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('extra_char', 'ghe.masorah'),\n",
       " ('char_swap', 'eh.masorah'),\n",
       " ('repeated_char', 'he.masorrah'),\n",
       " ('extra_char', 'he.masiorah'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('extra_char', 'hwe.masorah'),\n",
       " ('repeated_char', 'he.mmasorah'),\n",
       " ('extra_char', 'he.mqasorah'),\n",
       " ('nearby_char', 'he.kasorah'),\n",
       " ('missing_char', 'h.masorah'),\n",
       " ('nearby_char', 'em.new.jps1917'),\n",
       " ('missing_char', 'en.new.jps117'),\n",
       " ('char_swap', 'en.nwe.jps1917'),\n",
       " ('repeated_char', 'en.new.jps11917'),\n",
       " ('extra_char', 'en.new.hjps1917'),\n",
       " ('repeated_char', 'en.new.jps19117'),\n",
       " ('missing_char', 'e.new.jps1917'),\n",
       " ('char_swap', 'en.new.jps9117'),\n",
       " ('extra_char', 'en.new.hjps1917'),\n",
       " ('nearby_char', 'en.new.jpe1917'),\n",
       " ('extra_char', 'en.mnew.jps1917'),\n",
       " ('extra_char', 'en.new.jps19167'),\n",
       " ('nearby_char', 'en.nww.jps1917'),\n",
       " ('char_swap', 'en.new.jsp1917'),\n",
       " ('repeated_char', 'en.new.jjps1917'),\n",
       " ('char_swap', 'en.nwe.jps1917'),\n",
       " ('missing_char', 'n.new.jps1917'),\n",
       " ('missing_char', 'en.nw.jps1917'),\n",
       " ('nearby_char', 'en.new.jpw1917'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('extra_char', 'en.okoren'),\n",
       " ('repeated_char', 'en.kkoren'),\n",
       " ('nearby_char', 'en.kkren'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('char_swap', 'en.kroen'),\n",
       " ('repeated_char', 'en.korren'),\n",
       " ('extra_char', 'en.korebn'),\n",
       " ('repeated_char', 'en.korenn'),\n",
       " ('char_swap', 'en.okren'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('missing_char', 'en.kore'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('repeated_char', 'he.text__only'),\n",
       " ('repeated_char', 'he.ttext_only'),\n",
       " ('repeated_char', 'he.text_onlyy'),\n",
       " ('char_swap', 'he.text_noly'),\n",
       " ('repeated_char', 'hhe.text_only'),\n",
       " ('missing_char', 'he.tex_only'),\n",
       " ('extra_char', 'he.text_ponly'),\n",
       " ('extra_char', 'he.ytext_only'),\n",
       " ('extra_char', 'he.text_onlty'),\n",
       " ('char_swap', 'eh.text_only'),\n",
       " ('repeated_char', 'he.text_onlyy'),\n",
       " ('extra_char', 'he.text_onluy'),\n",
       " ('nearby_char', 'he.trxt_only'),\n",
       " ('nearby_char', 'he.text_obly'),\n",
       " ('extra_char', 'he.ftext_only'),\n",
       " ('char_swap', 'he.tex_tonly'),\n",
       " ('nearby_char', 'be.text_only'),\n",
       " ('char_swap', 'he.masroah'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('repeated_char', 'he.masorahh'),\n",
       " ('extra_char', 'he.maesorah'),\n",
       " ('char_swap', 'he.masorha'),\n",
       " ('extra_char', 'he.maasorah'),\n",
       " ('extra_char', 'he.maskorah'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('nearby_char', 'he.masorqh'),\n",
       " ('missing_char', 'e.masorah'),\n",
       " ('missing_char', 'he.asorah'),\n",
       " ('extra_char', 'he.maxsorah'),\n",
       " ('missing_char', 'e.masorah'),\n",
       " ('extra_char', 'he.masodrah'),\n",
       " ('extra_char', 'he.maskorah'),\n",
       " ('missing_char', 'he.masoah'),\n",
       " ('nearby_char', 'he.mzsorah'),\n",
       " ('repeated_char', 'hhe.masorah'),\n",
       " ('nearby_char', 'hd.masorah'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('nearby_char', 'be.masorah'),\n",
       " ('extra_char', 'en.new.jops1917'),\n",
       " ('extra_char', 'en.nrew.jps1917'),\n",
       " ('char_swap', 'en.new.pjs1917'),\n",
       " ('nearby_char', 'en.new.jpd1917'),\n",
       " ('nearby_char', 'en.nsw.jps1917'),\n",
       " ('repeated_char', 'en.new.jpss1917'),\n",
       " ('missing_char', 'en.new.js1917'),\n",
       " ('extra_char', 'den.new.jps1917'),\n",
       " ('repeated_char', 'enn.new.jps1917'),\n",
       " ('nearby_char', 'en.new.jps1817'),\n",
       " ('nearby_char', 'en.new.jps1927'),\n",
       " ('nearby_char', 'en.new.jps11017'),\n",
       " ('repeated_char', 'en.new.jps19117'),\n",
       " ('extra_char', 'en.nrew.jps1917'),\n",
       " ('repeated_char', 'en.new.jps19177'),\n",
       " ('missing_char', 'n.new.jps1917'),\n",
       " ('extra_char', 'en.new.jps19017'),\n",
       " ('missing_char', 'n.new.jps1917'),\n",
       " ('nearby_char', 'sn.new.jps1917'),\n",
       " ('missing_char', 'en.new.jps117'),\n",
       " ('extra_char', 'en.kporen'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('repeated_char', 'en.korren'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('repeated_char', 'en.koreen'),\n",
       " ('nearby_char', 'en.koten'),\n",
       " ('extra_char', 'en.kofren'),\n",
       " ('repeated_char', 'en.kooren'),\n",
       " ('repeated_char', 'enn.koren'),\n",
       " ('nearby_char', 'en.korej'),\n",
       " ('repeated_char', 'en.kkoren'),\n",
       " ('extra_char', 'en.okoren'),\n",
       " ('nearby_char', 'en.koreb'),\n",
       " ('extra_char', 'en.kloren'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('nearby_char', 'en.kiren'),\n",
       " ('missing_char', 'en.korn'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('extra_char', 'en.kioren'),\n",
       " ('missing_char', 'en.kore'),\n",
       " ('missing_char', 'e.koren'),\n",
       " ('missing_char', 'en.korn'),\n",
       " ('repeated_char', 'en.kkoren'),\n",
       " ('missing_char', 'e.koren'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('repeated_char', 'he.text_onnly'),\n",
       " ('nearby_char', 'he.yext_only'),\n",
       " ('repeated_char', 'he.text_oonly'),\n",
       " ('missing_char', 'h.text_only'),\n",
       " ('repeated_char', 'he.text_onlyy'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('extra_char', 'he.tedxt_only'),\n",
       " ('repeated_char', 'he.textt_only'),\n",
       " ('repeated_char', 'he.text_onlyy'),\n",
       " ('char_swap', 'he.text_onyl'),\n",
       " ('missing_char', 'h.text_only'),\n",
       " ('nearby_char', 'he.masorau'),\n",
       " ('extra_char', 'ghe.masorah'),\n",
       " ('extra_char', 'he.msasorah'),\n",
       " ('repeated_char', 'he.masoraah'),\n",
       " ('missing_char', 'h.masorah'),\n",
       " ('nearby_char', 'hd.masorah'),\n",
       " ('char_swap', 'he.masorha'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('extra_char', 'hre.masorah'),\n",
       " ('nearby_char', 'he.masorag'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('extra_char', 'he.nmasorah'),\n",
       " ('missing_char', 'he.asorah'),\n",
       " ('missing_char', 'he.maorah'),\n",
       " ('extra_char', 'he.mzasorah'),\n",
       " ('extra_char', 'he.masorabh'),\n",
       " ('char_swap', 'en.new.jsp1917'),\n",
       " ('char_swap', 'en.new.jps9117'),\n",
       " ('repeated_char', 'een.new.jps1917'),\n",
       " ('repeated_char', 'en.new.jps19917'),\n",
       " ('repeated_char', 'en.new.jps11917'),\n",
       " ('repeated_char', 'enn.new.jps1917'),\n",
       " ('missing_char', 'en.ew.jps1917'),\n",
       " ('nearby_char', 'en.new.jps2917'),\n",
       " ('missing_char', 'en.ew.jps1917'),\n",
       " ('nearby_char', 'eh.new.jps1917'),\n",
       " ('extra_char', 'en.nrew.jps1917'),\n",
       " ('nearby_char', 'eb.new.jps1917'),\n",
       " ('char_swap', 'en.new.pjs1917'),\n",
       " ('nearby_char', 'en.new.jos1917'),\n",
       " ('nearby_char', 'en.nrw.jps1917'),\n",
       " ('repeated_char', 'en.new.jps11917'),\n",
       " ('missing_char', 'en.kore'),\n",
       " ('nearby_char', 'en.joren'),\n",
       " ('missing_char', 'en.oren'),\n",
       " ('char_swap', 'en.kroen'),\n",
       " ('char_swap', 'en.okren'),\n",
       " ('repeated_char', 'en.koreen'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('nearby_char', 'en.kofen'),\n",
       " ('extra_char', 'ejn.koren'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('nearby_char', 'en.koreh'),\n",
       " ('extra_char', 'en.lkoren'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('repeated_char', 'en.korenn'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('extra_char', 'he.texrt_only'),\n",
       " ('nearby_char', 'he.text_onoy'),\n",
       " ('repeated_char', 'hhe.text_only'),\n",
       " ('missing_char', 'he.txt_only'),\n",
       " ('nearby_char', 'he.text_ohly'),\n",
       " ('extra_char', 'he.texft_only'),\n",
       " ('char_swap', 'he.text_olny'),\n",
       " ('char_swap', 'he.text_onyl'),\n",
       " ('extra_char', 'he.text_onply'),\n",
       " ('repeated_char', 'he.text_onlyy'),\n",
       " ('missing_char', 'he.tex_only'),\n",
       " ('missing_char', 'he.tet_only'),\n",
       " ('repeated_char', 'he.ttext_only'),\n",
       " ('missing_char', 'he.textonly'),\n",
       " ('missing_char', 'he.text_oly'),\n",
       " ('char_swap', 'he.texto_nly'),\n",
       " ('extra_char', 'he.text__only'),\n",
       " ('extra_char', 'hse.text_only'),\n",
       " ('repeated_char', 'he.text_oonly'),\n",
       " ('extra_char', 'he.rtext_only'),\n",
       " ('repeated_char', 'he.masoraah'),\n",
       " ('extra_char', 'he.maskorah'),\n",
       " ('nearby_char', 'he.masodah'),\n",
       " ('char_swap', 'he.maosrah'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('missing_char', 'he.maorah'),\n",
       " ('extra_char', 'he.mqasorah'),\n",
       " ('extra_char', 'he.masofrah'),\n",
       " ('repeated_char', 'he.mmasorah'),\n",
       " ('nearby_char', 'ne.masorah'),\n",
       " ('missing_char', 'he.masoah'),\n",
       " ('repeated_char', 'he.mmasorah'),\n",
       " ('extra_char', 'he.masorsah'),\n",
       " ('repeated_char', 'he.masoraah'),\n",
       " ('extra_char', 'he.nmasorah'),\n",
       " ('char_swap', 'eh.masorah'),\n",
       " ('extra_char', 'he.maskorah'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('extra_char', 'he.maxsorah'),\n",
       " ('char_swap', 'he.amsorah'),\n",
       " ('extra_char', 'hwe.masorah'),\n",
       " ('extra_char', 'he.masorajh'),\n",
       " ('extra_char', 'en.new.njps1917'),\n",
       " ('extra_char', 'en.new.jps18917'),\n",
       " ('char_swap', 'en.new.jps9117'),\n",
       " ('missing_char', 'en.new.jp1917'),\n",
       " ('missing_char', 'en.new.js1917'),\n",
       " ('nearby_char', 'en.new.jps1914'),\n",
       " ('repeated_char', 'enn.new.jps1917'),\n",
       " ('nearby_char', 'en.new.jpx1917'),\n",
       " ('char_swap', 'en.new.jps9117'),\n",
       " ('char_swap', 'en.new.jps1197'),\n",
       " ('nearby_char', 'en.new.kps1917'),\n",
       " ('extra_char', 'en.new.jpxs1917'),\n",
       " ('char_swap', 'en.new.jsp1917'),\n",
       " ('repeated_char', 'en.new.jps11917'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('missing_char', 'en.korn'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('nearby_char', 'en.korsn'),\n",
       " ('extra_char', 'en.kioren'),\n",
       " ('missing_char', 'n.koren'),\n",
       " ('char_swap', 'en.okren'),\n",
       " ('extra_char', 'ren.koren'),\n",
       " ('nearby_char', 'en.kiren'),\n",
       " ('missing_char', 'en.kore'),\n",
       " ('repeated_char', 'en.kooren'),\n",
       " ('missing_char', 'en.kore'),\n",
       " ('repeated_char', 'en.kooren'),\n",
       " ('repeated_char', 'en.koreen'),\n",
       " ('missing_char', 'en.kore'),\n",
       " ('extra_char', 'den.koren'),\n",
       " ('missing_char', 'en.kren'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('extra_char', 'en.koremn'),\n",
       " ('repeated_char', 'enn.koren'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('char_swap', 'en.kroen'),\n",
       " ('extra_char', 'he.rtext_only'),\n",
       " ('char_swap', 'he.tetx_only'),\n",
       " ('missing_char', 'e.text_only'),\n",
       " ('extra_char', 'he.text_onluy'),\n",
       " ('extra_char', 'he.text_ionly'),\n",
       " ('extra_char', 'he.ftext_only'),\n",
       " ('missing_char', 'he.ext_only'),\n",
       " ('extra_char', 'he.gtext_only'),\n",
       " ('missing_char', 'he.textonly'),\n",
       " ('extra_char', 'he.text__only'),\n",
       " ('missing_char', 'he.tex_only'),\n",
       " ('missing_char', 'he.text_onl'),\n",
       " ('nearby_char', 'he.text_obly'),\n",
       " ('char_swap', 'he.tex_tonly'),\n",
       " ('repeated_char', 'he.text__only'),\n",
       " ('nearby_char', 'hs.text_only'),\n",
       " ('nearby_char', 'he.gext_only'),\n",
       " ('extra_char', 'he.text_ohnly'),\n",
       " ('nearby_char', 'he.twxt_only'),\n",
       " ('nearby_char', 'he.text_omly'),\n",
       " ('extra_char', 'he.text__only'),\n",
       " ('char_swap', 'he.tex_tonly'),\n",
       " ('char_swap', 'he.msaorah'),\n",
       " ('missing_char', 'he.masora'),\n",
       " ('char_swap', 'eh.masorah'),\n",
       " ('missing_char', 'he.masoah'),\n",
       " ('extra_char', 'he.kmasorah'),\n",
       " ('char_swap', 'he.masroah'),\n",
       " ('repeated_char', 'he.maasorah'),\n",
       " ('nearby_char', 'he.masirah'),\n",
       " ('char_swap', 'eh.masorah'),\n",
       " ('missing_char', 'he.maorah'),\n",
       " ('repeated_char', 'he.massorah'),\n",
       " ('missing_char', 'he.maorah'),\n",
       " ('repeated_char', 'hhe.masorah'),\n",
       " ('extra_char', 'he.masporah'),\n",
       " ('repeated_char', 'he.masoorah'),\n",
       " ('char_swap', 'eh.masorah'),\n",
       " ('extra_char', 'he.masorauh'),\n",
       " ('extra_char', 'he.maasorah'),\n",
       " ('missing_char', 'en.ew.jps1917'),\n",
       " ('repeated_char', 'en.new.jps19117'),\n",
       " ('repeated_char', 'en.new.jps19117'),\n",
       " ('repeated_char', 'en.new.jps19177'),\n",
       " ('char_swap', 'en.enw.jps1917'),\n",
       " ('extra_char', 'en.new.jps19187'),\n",
       " ('repeated_char', 'en.new.jps19117'),\n",
       " ('char_swap', 'en.new.jps9117'),\n",
       " ('nearby_char', 'en.new.jpe1917'),\n",
       " ('missing_char', 'en.new.jps117'),\n",
       " ('nearby_char', 'eb.new.jps1917'),\n",
       " ('nearby_char', 'en.new.nps1917'),\n",
       " ('missing_char', 'en.new.js1917'),\n",
       " ('nearby_char', 'sn.new.jps1917'),\n",
       " ('missing_char', 'en.new.jps117'),\n",
       " ('missing_char', 'en.ew.jps1917'),\n",
       " ('extra_char', 'en.new.jps16917'),\n",
       " ('missing_char', 'n.new.jps1917'),\n",
       " ('nearby_char', 'en.nea.jps1917'),\n",
       " ('char_swap', 'en.nwe.jps1917'),\n",
       " ('char_swap', 'en.new.pjs1917'),\n",
       " ('repeated_char', 'en.nnew.jps1917'),\n",
       " ('char_swap', 'en.nwe.jps1917'),\n",
       " ('nearby_char', 'en.ndw.jps1917'),\n",
       " ('nearby_char', 'en.new.jps1947'),\n",
       " ('missing_char', 'n.new.jps1917'),\n",
       " ('nearby_char', 'eb.koren'),\n",
       " ('missing_char', 'en.korn'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('extra_char', 'en.kofren'),\n",
       " ('repeated_char', 'en.korenn'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('repeated_char', 'enn.koren'),\n",
       " ('missing_char', 'en.korn'),\n",
       " ('char_swap', 'en.korne'),\n",
       " ('char_swap', 'en.koern'),\n",
       " ('missing_char', 'en.korn'),\n",
       " ('nearby_char', 'eh.koren'),\n",
       " ('nearby_char', 'ej.koren'),\n",
       " ('nearby_char', 'em.koren'),\n",
       " ('extra_char', 'en.korejn'),\n",
       " ('repeated_char', 'enn.koren'),\n",
       " ('char_swap', 'ne.koren'),\n",
       " ('extra_char', 'sen.koren'),\n",
       " ('missing_char', 'e.koren'),\n",
       " ('nearby_char', 'en.korej'),\n",
       " ('nearby_char', 'en.kofen')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ex['metadata']['typo_class'],ex['metadata']['wrong_args']['version']) for ex in examples if ex['metadata']['scenario']=='lookup_verse_typo_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "722a677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([ex['messages'][0]['role'] for ex in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a99f31a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [{'role': 'system',\n",
       "    'content': 'You are a research assistant that always responds using a JSON object with fields \"tool\" and \"arguments\".\\n\\nTo respond normally to the user, use:\\n{\"tool\": \"respond_to_user\", \"arguments\":{\"text\": \"<text to show the user>\"}}\\n\\nTo call a tool, use:\\n{\"tool\": \"<tool_name>\", \"arguments\":{ ... }}\\n\\nAfter you call a tool, you will receive a message with role \"user\" containing a JSON object.\\nThe tool message always includes \"tool_name\" and \"status\".\\n\\nIf \"status\" is \"ok\":\\n- The message will include a \"result\" object.\\n- Read \"result.text\".\\n- Respond using \"respond_to_user\" and copy \"result.text\" exactly as-is.\\n\\nIf \"status\" is \"error\":\\n- The message will include an \"error_message\".\\n- If the error message is clear enough (e.g., if the user spelled a book name wrong and it is clear which book the user intended), you can call the tool again with the corrected arguments.\\n- Otherwise, respond using \"respond_to_user\" and copy \"error_message\" exactly as-is (to let the user tell you what to do next).\\n\\nRules:\\n- Never modify, translate, summarize, or explain text returned by the tool.\\n- Never add commentary or extra text.\\n- Never guess missing arguments.\\n- Never correct user mistakes on the first attempt of a tool call.\\n- Never retry a failed tool call with exactly the same arguments.\\n\\nAvailable tool:\\n\\nTo get the text of a specific biblical verse:\\n{\"tool\": \"lookup_verse\", \"arguments\":{\"version\":\"<version>\", book:\"<book>\", chapter_num:<integer>, verse_num:<integer>}}\\nWhen this tool call succeeds, contains the verse. Copy it exactly as-is and return to the user with \"respond_to_user\".\\n\\n'},\n",
       "   {'role': 'user', 'content': 'Hi there, what can you help me with?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'I can assist you with analyzing biblical texts.'}],\n",
       "  'metadata': {'scenario': 'chitchat'}},\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': 'You are a research assistant that always responds using a JSON object with fields \"tool\" and \"arguments\".\\n\\nTo respond normally to the user, use:\\n{\"tool\": \"respond_to_user\", \"arguments\":{\"text\": \"<text to show the user>\"}}\\n\\nTo call a tool, use:\\n{\"tool\": \"<tool_name>\", \"arguments\":{ ... }}\\n\\nAfter you call a tool, you will receive a message with role \"user\" containing a JSON object.\\nThe tool message always includes \"tool_name\" and \"status\".\\n\\nIf \"status\" is \"ok\":\\n- The message will include a \"result\" object.\\n- Read \"result.text\".\\n- Respond using \"respond_to_user\" and copy \"result.text\" exactly as-is.\\n\\nIf \"status\" is \"error\":\\n- The message will include an \"error_message\".\\n- If the error message is clear enough (e.g., if the user spelled a book name wrong and it is clear which book the user intended), you can call the tool again with the corrected arguments.\\n- Otherwise, respond using \"respond_to_user\" and copy \"error_message\" exactly as-is (to let the user tell you what to do next).\\n\\nRules:\\n- Never modify, translate, summarize, or explain text returned by the tool.\\n- Never add commentary or extra text.\\n- Never guess missing arguments.\\n- Never correct user mistakes on the first attempt of a tool call.\\n- Never retry a failed tool call with exactly the same arguments.\\n\\nAvailable tool:\\n\\nTo get the text of a specific biblical verse:\\n{\"tool\": \"lookup_verse\", \"arguments\":{\"version\":\"<version>\", book:\"<book>\", chapter_num:<integer>, verse_num:<integer>}}\\nWhen this tool call succeeds, contains the verse. Copy it exactly as-is and return to the user with \"respond_to_user\".\\n\\n'},\n",
       "   {'role': 'user', 'content': 'Hello'},\n",
       "   {'role': 'assistant', 'content': 'Hi. How can I help you?'}],\n",
       "  'metadata': {'scenario': 'chitchat'}}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109fd85",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a53e8a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lookup_verse.3.test.jsonl', 'lookup_verse.3.train.jsonl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_folder = os.path.abspath(\"../data/dev\")\n",
    "os.listdir(dev_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e9223e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff: 1322\n"
     ]
    }
   ],
   "source": [
    "trainset_file = os.path.join(dev_folder, \"lookup_verse.3.train.jsonl\")\n",
    "testset_file = os.path.join(dev_folder, \"lookup_verse.3.test.jsonl\")\n",
    "cutoff = int(len(examples)*0.75)\n",
    "print(f\"Cutoff: {cutoff}\")\n",
    "\n",
    "with open(trainset_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in examples[:cutoff]:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(testset_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for ex in examples[cutoff:]:\n",
    "        f.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c8972c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a03d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
